"""
Enterprise RAG Chatbot - Streamlit Frontend
Updated to use new RAG Pipeline architecture with modular components
"""
import streamlit as st
import requests
import json
from typing import List, Dict, Any
import time
from pathlib import Path
import sys

# Add paths
sys.path.append(str(Path(__file__).parent.parent.parent))
sys.path.append(str(Path(__file__).parent.parent))

# Import components
from components.chat_interface import render_chat_interface, get_chat_input, render_quick_questions, render_chat_message
from components.document_upload import render_upload_interface, render_document_status
from components.system_monitor import render_system_monitor, render_model_settings, render_performance_metrics

# Try to import config, fallback to default values
try:
    from config.environment import env_center
    API_BASE_URL = f"http://{env_center.server_config.api_host}:{env_center.server_config.api_port}"
except:
    API_BASE_URL = "http://localhost:8000"

# Page config
st.set_page_config(
    page_title="Enterprise RAG Chatbot",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

def call_api(endpoint: str, method: str = "GET", data: Dict = None, files: Dict = None) -> Dict:
    """Make API call to backend"""
    url = f"{API_BASE_URL}{endpoint}"
    
    try:
        if method == "GET":
            response = requests.get(url)
        elif method == "POST":
            if files:
                response = requests.post(url, files=files, data=data)
            else:
                response = requests.post(url, json=data)
        elif method == "DELETE":
            response = requests.delete(url)
        else:
            raise ValueError(f"Unsupported method: {method}")
        
        response.raise_for_status()
        return response.json()
    
    except requests.exceptions.ConnectionError:
        st.error("üö´ Cannot connect to backend API. Please make sure the API server is running.")
        return {"error": "Connection failed"}
    except requests.exceptions.HTTPError as e:
        st.error(f"‚ùå API Error: {e}")
        return {"error": str(e)}
    except Exception as e:
        st.error(f"‚ö†Ô∏è Unexpected error: {e}")
        return {"error": str(e)}

def display_source(source: Dict, index: int):
    """Display a source document"""
    with st.expander(f"üìÑ Source {index + 1} (Similarity: {source['similarity_score']:.3f})"):
        st.write("**Content:**")
        st.write(source['content'])
        
        st.write("**Metadata:**")
        metadata = source['metadata']
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(f"**File:** {metadata.get('source_file', 'Unknown')}")
            st.write(f"**Type:** {metadata.get('file_type', 'Unknown')}")
        
        with col2:
            st.write(f"**Language:** {metadata.get('language_detected', 'Unknown')}")
            st.write(f"**Chunk Size:** {metadata.get('chunk_size', 0)} chars")

def main():
    st.title("ü§ñ Enterprise RAG Chatbot")
    st.markdown("AI-powered document search with multi-language OCR support")
    
    # Sidebar - System Monitor
    with st.sidebar:
        render_system_monitor(API_BASE_URL)
        st.divider()
        render_document_status(API_BASE_URL)
    
    # Main content tabs
    tab1, tab2, tab3, tab4 = st.tabs(["üí¨ Chat", "üì§ Upload Documents", "üìä System Monitor", "‚öôÔ∏è Settings"])
    
    with tab1:
        st.header("üí¨ Chat Interface")
        
        # Initialize conversation history
        if "conversation_history" not in st.session_state:
            st.session_state.conversation_history = []
        
        # Model selection
        try:
            models_data = call_api("/models")
            available_models = list(models_data.get("available_models", {}).keys()) if "error" not in models_data else []
        except:
            available_models = []
        
        if available_models:
            selected_model = st.selectbox("ü§ñ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• AI:", available_models)
        else:
            selected_model = None
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        
        # Quick questions
        quick_question = render_quick_questions()
        
        # Display chat history
        render_chat_interface(st.session_state.conversation_history)
        
        # Handle user input (quick question or chat input)
        user_input = quick_question or get_chat_input()
        
        if user_input and available_models:
            # Add user message
            user_message = {
                "role": "user",
                "content": user_input,
                "timestamp": time.strftime("%H:%M:%S")
            }
            st.session_state.conversation_history.append(user_message)
            
            # Display user message
            render_chat_message(user_message, is_user=True)
            
            # Get AI response
            with st.spinner("ü§î ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î..."):
                query_data = {
                    "question": user_input,
                    "conversation_history": [
                        {"role": msg["role"], "content": msg["content"]} 
                        for msg in st.session_state.conversation_history[:-1]
                    ] if len(st.session_state.conversation_history) > 1 else None,
                    "model_preference": selected_model
                }
                
                response_data = call_api("/query", "POST", query_data)
                
                if "error" not in response_data:
                    # Create assistant message
                    assistant_message = {
                        "role": "assistant",
                        "content": response_data["answer"],
                        "sources": response_data.get("sources", []),
                        "metadata": {
                            "processing_time": response_data.get("processing_time", 0),
                            "confidence_score": response_data.get("confidence_score", 0),
                            "model_used": response_data.get("model_used", "Unknown")
                        },
                        "timestamp": time.strftime("%H:%M:%S")
                    }
                    
                    st.session_state.conversation_history.append(assistant_message)
                    
                    # Display assistant message
                    render_chat_message(assistant_message, is_user=False)
                    
                else:
                    st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {response_data['error']}")
        
        # Chat controls
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", type="secondary"):
                st.session_state.conversation_history = []
                st.rerun()
        
        with col2:
            if st.button("ÔøΩ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", type="secondary"):
                if st.session_state.conversation_history:
                    # This could be implemented to save conversation
                    st.info("üí° ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï")
    
    with tab2:
        st.header("üì§ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£")
        
        # Document upload interface
        upload_result = render_upload_interface(API_BASE_URL)
        
        if upload_result:
            st.balloons()  # Celebration for successful upload
    
    with tab3:
        st.header("üìä ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö")
        
        # Performance metrics
        render_performance_metrics(API_BASE_URL)
        
        st.divider()
        
        # Detailed system monitor
        render_system_monitor(API_BASE_URL)
    
    with tab4:
        st.header("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö")
        
        # Model settings
        render_model_settings(API_BASE_URL)
        
        st.divider()
        
        # System controls
        st.subheader("üóÑÔ∏è ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üóëÔ∏è ‡∏•‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", type="secondary"):
                if st.button("‚ö†Ô∏è ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏ö", type="primary"):
                    with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£..."):
                        response_data = call_api("/documents", "DELETE")
                        if "error" not in response_data:
                            st.success("‚úÖ ‡∏•‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                            st.rerun()
                        else:
                            st.error(f"‚ùå ‡∏•‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {response_data['error']}")
        
        with col2:
            if st.button("ÔøΩ ‡∏£‡∏µ‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó‡∏£‡∏∞‡∏ö‡∏ö", type="secondary"):
                st.info("‚ÑπÔ∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏µ‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó API Server ‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏ô‡πÄ‡∏≠‡∏á")
        
        st.divider()
        
        # Environment validation  
        st.subheader("üîß ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")
        
        if st.button("ÔøΩ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°"):
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö..."):
                try:
                    from config.environment import env_center
                    validations = env_center.validate_environment()
                    
                    st.write("**‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Services:**")
                    for service, status in validations.items():
                        icon = "‚úÖ" if status else "‚ùå"
                        service_name = service.replace("_configured", "").replace("_", " ").title()
                        st.write(f"{icon} {service_name}")
                
                except Exception as e:
                    st.error(f"‚ùå ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")

if __name__ == "__main__":
    main()